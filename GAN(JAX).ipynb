{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sineeli/GANs-JAX/blob/main/GAN(JAX).ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsnWFZfXDge"
      },
      "source": [
        "## Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nB578mWFZAA"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import random, grad\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import flax\n",
        "\n",
        "from typing import Any\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "macN_pGxhoMl"
      },
      "source": [
        "## Base Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dU5HeGDFlvL"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "learning_rate = 0.0002\n",
        "noise_dim = 512\n",
        "label_smoothing = 0.95\n",
        "\n",
        "# Create random seed\n",
        "key = random.PRNGKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54BUnpiyhrbQ"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwDQAqP5FxEI"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, z):\n",
        "    x = nn.Dense(256)(z)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(512)(x)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(1024)(x)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(28*28)(x)\n",
        "    x = nn.tanh(x)\n",
        "    return x.reshape((-1, 28, 28, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwySPxgLhtcE"
      },
      "source": [
        "## Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPnzwJGXF_qx"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = x.reshape((-1, 28*28))\n",
        "    x = nn.Dense(1024)(x)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(512)(x)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(256)(x)\n",
        "    x = nn.leaky_relu(x, 0.2)\n",
        "    x = nn.Dense(1)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkmtIFHXh1mY"
      },
      "source": [
        "## Discriminator Training Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR9NTVVbhmTB"
      },
      "outputs": [],
      "source": [
        "@partial(jax.jit, static_argnames=['batch_size'])\n",
        "def discriminator_step(generator_state,\n",
        "                       discriminator_state,\n",
        "                       real_data,\n",
        "                       batch_size,\n",
        "                       key):\n",
        "  \"\"\"\n",
        "    Perform a single training step for the discriminator in a GAN.\n",
        "\n",
        "    This function generates fake images using the generator, combines them with real data,\n",
        "    and updates the discriminator's parameters based on the computed loss.\n",
        "\n",
        "    Args:\n",
        "        generator_state (TrainState): The current state of the generator, including parameters.\n",
        "        discriminator_state (TrainState): The current state of the discriminator, including parameters.\n",
        "        real_data (jax.numpy.ndarray): The batch of real data.\n",
        "        batch_size (int): The size of the batch.\n",
        "        key (jax.random.PRNGKey): A key for random number generation in JAX.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[TrainState, jnp.ndarray]: A tuple containing the updated discriminator state and the computed loss.\n",
        "  \"\"\"\n",
        "  def disc_loss_fn(params_disc, x, y):\n",
        "    # Apply the discriminator model to input data x with parameters params_disc\n",
        "    y_pred = discriminator.apply({'params': params_disc}, x)\n",
        "    # Calculate the binary cross-entropy loss\n",
        "    loss = optax.sigmoid_binary_cross_entropy(y_pred, y).mean()\n",
        "    return loss\n",
        "\n",
        "  # Generate random noise and produce fake images using the generator\n",
        "  z = random.normal(key, (batch_size, noise_dim))\n",
        "  fake_images = generator.apply({'params': generator_state.params}, z)\n",
        "\n",
        "  # Create fake labels (0) and real labels (1, with label smoothing)\n",
        "  fake_labels = jnp.zeros((batch_size, 1), float)\n",
        "  real_labels = label_smoothing * jnp.ones((batch_size, 1), float)\n",
        "\n",
        "  # Combine real and fake labels, as well as real and fake images\n",
        "  combined_labels = jnp.concatenate([real_labels, fake_labels], axis=0)\n",
        "  combined_images = jnp.concatenate([data, fake_images], axis=0)\n",
        "\n",
        "  # Define a gradient function for the discriminator loss\n",
        "  grad_fn = jax.value_and_grad(disc_loss_fn)\n",
        "  # Compute the loss and gradients for the combined real and fake data\n",
        "  loss, grads = grad_fn(discriminator_state.params,\n",
        "                        combined_images,\n",
        "                        combined_labels)\n",
        "\n",
        "  # Update the discriminator state with the computed gradients\n",
        "  new_discriminator_state = discriminator_state.apply_gradients(grads=grads)\n",
        "\n",
        "  return new_discriminator_state, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9gYj3EBh4PG"
      },
      "source": [
        "## Generator Training Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6vJXIir-TXV"
      },
      "outputs": [],
      "source": [
        "@partial(jax.jit, static_argnames=['batch_size'])\n",
        "def generator_step(generator_state,\n",
        "                   discriminator_state,\n",
        "                   batch_size,\n",
        "                   key):\n",
        "  \"\"\"\n",
        "    Perform a single step of training on the generator in a GAN setup.\n",
        "\n",
        "    This function computes the loss for the generator based on the output of the discriminator,\n",
        "    updates the generator's parameters using the computed gradients, and returns the updated\n",
        "    generator state along with the loss.\n",
        "\n",
        "    Args:\n",
        "        generator_state (TrainState): The current state of the generator, including parameters.\n",
        "        discriminator_state (TrainState): The current state of the discriminator, including parameters.\n",
        "        batch_size (int): The size of the batch to generate.\n",
        "        key (jax.random.PRNGKey): A key for random number generation in JAX.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[TrainState, jnp.ndarray]: A tuple containing the updated generator state and the computed loss.\n",
        "  \"\"\"\n",
        "\n",
        "  def gen_loss_fn(params, z):\n",
        "    # Generate fake images using the current generator parameters\n",
        "    fake_images = generator.apply({'params': params}, z)\n",
        "    # Compute the discriminator's logits for these fake images\n",
        "    logits = discriminator.apply({'params': discriminator_state.params}, fake_images)\n",
        "    # Calculate the generator's loss as the negative log likelihood\n",
        "    loss = -jnp.mean(jnp.log(nn.sigmoid(logits)))\n",
        "\n",
        "    return loss\n",
        "\n",
        "  # Generate random noise as input for the generator\n",
        "  z = random.normal(key, (batch_size, noise_dim))\n",
        "  # Define a function to compute both the loss and gradients for the generator\n",
        "  grad_fn = jax.value_and_grad(gen_loss_fn)\n",
        "  # Calculate the loss and gradients based on the current generator parameters\n",
        "  loss, grads = grad_fn(generator_state.params, z)\n",
        "  # Update the generator state with the computed gradients\n",
        "  new_generator_state = generator_state.apply_gradients(grads=grads)\n",
        "\n",
        "  return new_generator_state, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIOUEUVekhQi"
      },
      "source": [
        "## Intialize and Get Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY4RyrlEGMr2"
      },
      "outputs": [],
      "source": [
        "# Initialize generator\n",
        "z = random.normal(key, (batch_size, noise_dim))\n",
        "generator = Generator()\n",
        "params_gen = generator.init(key, z)['params']\n",
        "\n",
        "# Initialize discriminator\n",
        "discriminator = Discriminator()\n",
        "params_disc = discriminator.init(key, jnp.ones([1, 28, 28, 1]))['params']\n",
        "\n",
        "# Optimizers\n",
        "tx_gen = optax.adam(learning_rate, b1=0.5)\n",
        "tx_disc = optax.adam(learning_rate, b1=0.5)\n",
        "\n",
        "# Training state\n",
        "generator_state = train_state.TrainState.create(apply_fn=generator.apply, params=params_gen, tx=tx_gen)\n",
        "discriminator_state = train_state.TrainState.create(apply_fn=discriminator.apply, params=params_disc, tx=tx_disc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdi_8qBhkki9"
      },
      "source": [
        "## Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1rbvy_Jhxko"
      },
      "outputs": [],
      "source": [
        "def set_range(batch):\n",
        "  batch = tf.image.convert_image_dtype(batch['image'], tf.float32)\n",
        "  batch = (batch - 0.5) / 0.5  # tanh range is -1, 1\n",
        "  return batch\n",
        "\n",
        "\n",
        "mnist_data = tfds.load(\"mnist\")['train']\n",
        "batches_in_epoch = len(mnist_data) // batch_size\n",
        "\n",
        "data_gen = iter(tfds.as_numpy(\n",
        "      mnist_data\n",
        "        .map(set_range)\n",
        "        .cache()\n",
        "        .shuffle(len(mnist_data), seed=42)\n",
        "        .batch(batch_size)\n",
        " ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB77dAS-knVv"
      },
      "source": [
        "## Train the GAN network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3WV085Hi4B",
        "outputId": "47b03327-5477-4bb8-fba8-f42f27e03b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator loss: 0.736 | Discriminator loss: 0.796\n",
            "Generator loss: 0.657 | Discriminator loss: 0.600\n",
            "Generator loss: 0.624 | Discriminator loss: 0.568\n",
            "Generator loss: 0.627 | Discriminator loss: 0.563\n",
            "Generator loss: 0.649 | Discriminator loss: 0.541\n",
            "Generator loss: 0.694 | Discriminator loss: 0.517\n",
            "Generator loss: 0.768 | Discriminator loss: 0.485\n",
            "Generator loss: 0.850 | Discriminator loss: 0.453\n",
            "Generator loss: 0.927 | Discriminator loss: 0.431\n",
            "Generator loss: 0.994 | Discriminator loss: 0.421\n",
            "Generator loss: 1.034 | Discriminator loss: 0.420\n",
            "Generator loss: 1.082 | Discriminator loss: 0.433\n",
            "Generator loss: 1.105 | Discriminator loss: 0.453\n",
            "Generator loss: 1.076 | Discriminator loss: 0.491\n",
            "Generator loss: 1.034 | Discriminator loss: 0.515\n",
            "Generator loss: 1.027 | Discriminator loss: 0.535\n",
            "Generator loss: 1.036 | Discriminator loss: 0.532\n",
            "Generator loss: 1.103 | Discriminator loss: 0.508\n",
            "Generator loss: 1.165 | Discriminator loss: 0.485\n",
            "Generator loss: 1.268 | Discriminator loss: 0.466\n",
            "Generator loss: 1.319 | Discriminator loss: 0.480\n",
            "Generator loss: 1.392 | Discriminator loss: 0.492\n",
            "Generator loss: 1.305 | Discriminator loss: 0.511\n",
            "Generator loss: 1.422 | Discriminator loss: 0.508\n",
            "Generator loss: 1.277 | Discriminator loss: 0.492\n",
            "Generator loss: 1.588 | Discriminator loss: 0.471\n",
            "Generator loss: 1.343 | Discriminator loss: 0.470\n",
            "Generator loss: 1.658 | Discriminator loss: 0.466\n",
            "Generator loss: 1.337 | Discriminator loss: 0.492\n",
            "Generator loss: 1.579 | Discriminator loss: 0.520\n",
            "Generator loss: 1.194 | Discriminator loss: 0.555\n",
            "Generator loss: 1.455 | Discriminator loss: 0.557\n",
            "Generator loss: 1.033 | Discriminator loss: 0.572\n",
            "Generator loss: 1.394 | Discriminator loss: 0.527\n",
            "Generator loss: 1.268 | Discriminator loss: 0.492\n",
            "Generator loss: 1.438 | Discriminator loss: 0.477\n",
            "Generator loss: 1.446 | Discriminator loss: 0.485\n",
            "Generator loss: 1.528 | Discriminator loss: 0.511\n",
            "Generator loss: 1.286 | Discriminator loss: 0.544\n",
            "Generator loss: 1.566 | Discriminator loss: 0.638\n",
            "Generator loss: 0.572 | Discriminator loss: 0.796\n",
            "Generator loss: 1.147 | Discriminator loss: 0.538\n",
            "Generator loss: 1.507 | Discriminator loss: 0.641\n",
            "Generator loss: 0.621 | Discriminator loss: 0.684\n",
            "Generator loss: 1.123 | Discriminator loss: 0.519\n",
            "Generator loss: 1.676 | Discriminator loss: 0.689\n",
            "Generator loss: 0.557 | Discriminator loss: 0.750\n",
            "Generator loss: 0.805 | Discriminator loss: 0.628\n",
            "Generator loss: 1.460 | Discriminator loss: 0.804\n",
            "Generator loss: 0.519 | Discriminator loss: 0.766\n",
            "Generator loss: 0.684 | Discriminator loss: 0.679\n",
            "Generator loss: 1.125 | Discriminator loss: 0.738\n",
            "Generator loss: 0.657 | Discriminator loss: 0.698\n",
            "Generator loss: 0.796 | Discriminator loss: 0.668\n",
            "Generator loss: 1.084 | Discriminator loss: 0.684\n",
            "Generator loss: 0.790 | Discriminator loss: 0.671\n",
            "Generator loss: 0.967 | Discriminator loss: 0.676\n",
            "Generator loss: 0.918 | Discriminator loss: 0.698\n",
            "Generator loss: 0.836 | Discriminator loss: 0.698\n",
            "Generator loss: 0.884 | Discriminator loss: 0.718\n",
            "Generator loss: 0.817 | Discriminator loss: 0.716\n",
            "Generator loss: 0.896 | Discriminator loss: 0.710\n",
            "Generator loss: 0.784 | Discriminator loss: 0.696\n",
            "Generator loss: 0.946 | Discriminator loss: 0.680\n",
            "Generator loss: 0.841 | Discriminator loss: 0.660\n",
            "Generator loss: 1.044 | Discriminator loss: 0.655\n",
            "Generator loss: 0.837 | Discriminator loss: 0.666\n",
            "Generator loss: 1.171 | Discriminator loss: 0.705\n",
            "Generator loss: 0.688 | Discriminator loss: 0.753\n",
            "Generator loss: 1.076 | Discriminator loss: 0.765\n",
            "Generator loss: 0.629 | Discriminator loss: 0.746\n",
            "Generator loss: 0.902 | Discriminator loss: 0.705\n",
            "Generator loss: 0.885 | Discriminator loss: 0.676\n",
            "Generator loss: 0.834 | Discriminator loss: 0.673\n",
            "Generator loss: 1.036 | Discriminator loss: 0.675\n",
            "Generator loss: 0.854 | Discriminator loss: 0.683\n",
            "Generator loss: 1.063 | Discriminator loss: 0.682\n",
            "Generator loss: 0.841 | Discriminator loss: 0.683\n",
            "Generator loss: 1.262 | Discriminator loss: 0.681\n",
            "Generator loss: 0.670 | Discriminator loss: 0.719\n",
            "Generator loss: 1.466 | Discriminator loss: 0.672\n",
            "Generator loss: 0.828 | Discriminator loss: 0.661\n",
            "Generator loss: 1.199 | Discriminator loss: 0.618\n",
            "Generator loss: 1.118 | Discriminator loss: 0.648\n",
            "Generator loss: 1.022 | Discriminator loss: 0.683\n",
            "Generator loss: 1.104 | Discriminator loss: 0.708\n",
            "Generator loss: 0.894 | Discriminator loss: 0.732\n",
            "Generator loss: 1.095 | Discriminator loss: 0.721\n",
            "Generator loss: 0.839 | Discriminator loss: 0.703\n",
            "Generator loss: 1.155 | Discriminator loss: 0.670\n",
            "Generator loss: 0.972 | Discriminator loss: 0.643\n",
            "Generator loss: 1.289 | Discriminator loss: 0.612\n",
            "Generator loss: 1.101 | Discriminator loss: 0.595\n",
            "Generator loss: 1.427 | Discriminator loss: 0.588\n",
            "Generator loss: 1.142 | Discriminator loss: 0.610\n",
            "Generator loss: 1.543 | Discriminator loss: 0.661\n",
            "Generator loss: 0.847 | Discriminator loss: 0.729\n",
            "Generator loss: 1.509 | Discriminator loss: 0.723\n",
            "Generator loss: 0.778 | Discriminator loss: 0.705\n",
            "Generator loss: 1.230 | Discriminator loss: 0.646\n",
            "Generator loss: 1.024 | Discriminator loss: 0.637\n",
            "Generator loss: 1.092 | Discriminator loss: 0.630\n",
            "Generator loss: 1.163 | Discriminator loss: 0.638\n",
            "Generator loss: 1.040 | Discriminator loss: 0.641\n",
            "Generator loss: 1.144 | Discriminator loss: 0.632\n",
            "Generator loss: 1.033 | Discriminator loss: 0.601\n",
            "Generator loss: 1.144 | Discriminator loss: 0.584\n",
            "Generator loss: 1.084 | Discriminator loss: 0.566\n",
            "Generator loss: 1.106 | Discriminator loss: 0.552\n",
            "Generator loss: 1.134 | Discriminator loss: 0.551\n",
            "Generator loss: 1.171 | Discriminator loss: 0.548\n",
            "Generator loss: 1.156 | Discriminator loss: 0.555\n",
            "Generator loss: 1.158 | Discriminator loss: 0.569\n",
            "Generator loss: 1.082 | Discriminator loss: 0.582\n",
            "Generator loss: 1.165 | Discriminator loss: 0.585\n",
            "Generator loss: 1.067 | Discriminator loss: 0.578\n",
            "Generator loss: 1.276 | Discriminator loss: 0.593\n",
            "Generator loss: 0.960 | Discriminator loss: 0.615\n",
            "Generator loss: 1.341 | Discriminator loss: 0.639\n",
            "Generator loss: 0.709 | Discriminator loss: 0.687\n",
            "Generator loss: 1.305 | Discriminator loss: 0.658\n",
            "Generator loss: 0.820 | Discriminator loss: 0.633\n",
            "Generator loss: 1.048 | Discriminator loss: 0.609\n",
            "Generator loss: 1.008 | Discriminator loss: 0.602\n",
            "Generator loss: 0.997 | Discriminator loss: 0.597\n",
            "Generator loss: 1.157 | Discriminator loss: 0.589\n",
            "Generator loss: 1.009 | Discriminator loss: 0.581\n",
            "Generator loss: 1.268 | Discriminator loss: 0.584\n",
            "Generator loss: 0.951 | Discriminator loss: 0.578\n",
            "Generator loss: 1.267 | Discriminator loss: 0.607\n",
            "Generator loss: 0.765 | Discriminator loss: 0.651\n",
            "Generator loss: 1.335 | Discriminator loss: 0.723\n",
            "Generator loss: 0.482 | Discriminator loss: 0.781\n",
            "Generator loss: 1.085 | Discriminator loss: 0.695\n",
            "Generator loss: 0.783 | Discriminator loss: 0.663\n",
            "Generator loss: 0.872 | Discriminator loss: 0.643\n",
            "Generator loss: 0.972 | Discriminator loss: 0.635\n",
            "Generator loss: 0.928 | Discriminator loss: 0.602\n",
            "Generator loss: 1.015 | Discriminator loss: 0.574\n",
            "Generator loss: 1.012 | Discriminator loss: 0.553\n",
            "Generator loss: 1.073 | Discriminator loss: 0.537\n",
            "Generator loss: 1.096 | Discriminator loss: 0.540\n",
            "Generator loss: 1.128 | Discriminator loss: 0.537\n",
            "Generator loss: 1.151 | Discriminator loss: 0.550\n",
            "Generator loss: 1.144 | Discriminator loss: 0.570\n",
            "Generator loss: 1.131 | Discriminator loss: 0.594\n",
            "Generator loss: 1.096 | Discriminator loss: 0.611\n",
            "Generator loss: 1.099 | Discriminator loss: 0.609\n",
            "Generator loss: 1.053 | Discriminator loss: 0.592\n",
            "Generator loss: 1.136 | Discriminator loss: 0.566\n",
            "Generator loss: 1.049 | Discriminator loss: 0.539\n",
            "Generator loss: 1.284 | Discriminator loss: 0.520\n",
            "Generator loss: 1.073 | Discriminator loss: 0.508\n",
            "Generator loss: 1.487 | Discriminator loss: 0.508\n",
            "Generator loss: 0.939 | Discriminator loss: 0.554\n",
            "Generator loss: 1.634 | Discriminator loss: 0.535\n",
            "Generator loss: 0.879 | Discriminator loss: 0.575\n",
            "Generator loss: 1.459 | Discriminator loss: 0.539\n",
            "Generator loss: 1.071 | Discriminator loss: 0.550\n",
            "Generator loss: 1.156 | Discriminator loss: 0.583\n",
            "Generator loss: 1.037 | Discriminator loss: 0.594\n",
            "Generator loss: 0.999 | Discriminator loss: 0.559\n",
            "Generator loss: 1.061 | Discriminator loss: 0.524\n",
            "Generator loss: 1.205 | Discriminator loss: 0.472\n",
            "Generator loss: 1.190 | Discriminator loss: 0.446\n",
            "Generator loss: 1.453 | Discriminator loss: 0.445\n",
            "Generator loss: 1.229 | Discriminator loss: 0.466\n",
            "Generator loss: 1.568 | Discriminator loss: 0.497\n",
            "Generator loss: 0.977 | Discriminator loss: 0.556\n",
            "Generator loss: 1.616 | Discriminator loss: 0.588\n",
            "Generator loss: 0.715 | Discriminator loss: 0.642\n",
            "Generator loss: 1.336 | Discriminator loss: 0.518\n",
            "Generator loss: 1.144 | Discriminator loss: 0.498\n",
            "Generator loss: 1.051 | Discriminator loss: 0.496\n",
            "Generator loss: 1.228 | Discriminator loss: 0.493\n",
            "Generator loss: 1.109 | Discriminator loss: 0.469\n",
            "Generator loss: 1.278 | Discriminator loss: 0.456\n",
            "Generator loss: 1.223 | Discriminator loss: 0.455\n",
            "Generator loss: 1.316 | Discriminator loss: 0.466\n",
            "Generator loss: 1.263 | Discriminator loss: 0.475\n",
            "Generator loss: 1.288 | Discriminator loss: 0.476\n",
            "Generator loss: 1.209 | Discriminator loss: 0.492\n",
            "Generator loss: 1.302 | Discriminator loss: 0.491\n",
            "Generator loss: 1.045 | Discriminator loss: 0.493\n",
            "Generator loss: 1.590 | Discriminator loss: 0.506\n",
            "Generator loss: 0.758 | Discriminator loss: 0.573\n",
            "Generator loss: 1.674 | Discriminator loss: 0.420\n",
            "Generator loss: 1.361 | Discriminator loss: 0.391\n",
            "Generator loss: 1.437 | Discriminator loss: 0.400\n",
            "Generator loss: 1.493 | Discriminator loss: 0.438\n",
            "Generator loss: 1.170 | Discriminator loss: 0.482\n",
            "Generator loss: 1.520 | Discriminator loss: 0.512\n",
            "Generator loss: 0.868 | Discriminator loss: 0.539\n",
            "Generator loss: 1.689 | Discriminator loss: 0.506\n",
            "Generator loss: 0.900 | Discriminator loss: 0.494\n",
            "Generator loss: 1.567 | Discriminator loss: 0.380\n",
            "Generator loss: 1.599 | Discriminator loss: 0.371\n",
            "Generator loss: 1.347 | Discriminator loss: 0.387\n",
            "Generator loss: 1.720 | Discriminator loss: 0.416\n",
            "Generator loss: 1.213 | Discriminator loss: 0.460\n",
            "Generator loss: 1.759 | Discriminator loss: 0.494\n",
            "Generator loss: 0.807 | Discriminator loss: 0.569\n",
            "Generator loss: 1.691 | Discriminator loss: 0.401\n",
            "Generator loss: 1.400 | Discriminator loss: 0.355\n",
            "Generator loss: 1.444 | Discriminator loss: 0.356\n",
            "Generator loss: 1.665 | Discriminator loss: 0.363\n",
            "Generator loss: 1.368 | Discriminator loss: 0.385\n",
            "Generator loss: 1.609 | Discriminator loss: 0.391\n",
            "Generator loss: 1.287 | Discriminator loss: 0.404\n",
            "Generator loss: 1.596 | Discriminator loss: 0.408\n",
            "Generator loss: 1.203 | Discriminator loss: 0.425\n",
            "Generator loss: 1.766 | Discriminator loss: 0.414\n",
            "Generator loss: 1.076 | Discriminator loss: 0.431\n",
            "Generator loss: 1.768 | Discriminator loss: 0.361\n",
            "Generator loss: 1.435 | Discriminator loss: 0.371\n",
            "Generator loss: 1.594 | Discriminator loss: 0.381\n",
            "Generator loss: 1.462 | Discriminator loss: 0.386\n",
            "Generator loss: 1.549 | Discriminator loss: 0.389\n",
            "Generator loss: 1.543 | Discriminator loss: 0.388\n",
            "Generator loss: 1.633 | Discriminator loss: 0.391\n",
            "Generator loss: 1.627 | Discriminator loss: 0.395\n",
            "Generator loss: 1.638 | Discriminator loss: 0.385\n",
            "Generator loss: 1.545 | Discriminator loss: 0.385\n",
            "Generator loss: 1.733 | Discriminator loss: 0.402\n",
            "Generator loss: 1.393 | Discriminator loss: 0.414\n",
            "Generator loss: 2.157 | Discriminator loss: 0.490\n",
            "Generator loss: 0.564 | Discriminator loss: 0.730\n",
            "Generator loss: 1.585 | Discriminator loss: 0.319\n",
            "Generator loss: 2.550 | Discriminator loss: 0.587\n",
            "Generator loss: 0.609 | Discriminator loss: 0.690\n",
            "Generator loss: 0.841 | Discriminator loss: 0.539\n",
            "Generator loss: 1.708 | Discriminator loss: 0.412\n",
            "Generator loss: 1.556 | Discriminator loss: 0.428\n",
            "Generator loss: 1.034 | Discriminator loss: 0.462\n",
            "Generator loss: 1.146 | Discriminator loss: 0.448\n",
            "Generator loss: 1.269 | Discriminator loss: 0.490\n",
            "Generator loss: 1.056 | Discriminator loss: 0.477\n",
            "Generator loss: 1.219 | Discriminator loss: 0.476\n",
            "Generator loss: 1.286 | Discriminator loss: 0.481\n",
            "Generator loss: 1.224 | Discriminator loss: 0.468\n",
            "Generator loss: 1.329 | Discriminator loss: 0.454\n",
            "Generator loss: 1.146 | Discriminator loss: 0.478\n",
            "Generator loss: 1.801 | Discriminator loss: 0.533\n",
            "Generator loss: 0.471 | Discriminator loss: 0.779\n",
            "Generator loss: 1.409 | Discriminator loss: 0.410\n",
            "Generator loss: 2.183 | Discriminator loss: 0.596\n",
            "Generator loss: 0.396 | Discriminator loss: 0.786\n",
            "Generator loss: 0.676 | Discriminator loss: 0.566\n",
            "Generator loss: 1.796 | Discriminator loss: 0.499\n",
            "Generator loss: 1.254 | Discriminator loss: 0.428\n",
            "Generator loss: 1.009 | Discriminator loss: 0.464\n",
            "Generator loss: 1.245 | Discriminator loss: 0.447\n",
            "Generator loss: 1.289 | Discriminator loss: 0.458\n",
            "Generator loss: 1.054 | Discriminator loss: 0.466\n",
            "Generator loss: 1.171 | Discriminator loss: 0.469\n",
            "Generator loss: 1.187 | Discriminator loss: 0.471\n",
            "Generator loss: 1.250 | Discriminator loss: 0.460\n",
            "Generator loss: 1.206 | Discriminator loss: 0.475\n",
            "Generator loss: 1.370 | Discriminator loss: 0.483\n",
            "Generator loss: 1.017 | Discriminator loss: 0.486\n",
            "Generator loss: 1.604 | Discriminator loss: 0.512\n",
            "Generator loss: 0.726 | Discriminator loss: 0.597\n",
            "Generator loss: 1.891 | Discriminator loss: 0.580\n",
            "Generator loss: 0.626 | Discriminator loss: 0.617\n",
            "Generator loss: 1.412 | Discriminator loss: 0.421\n",
            "Generator loss: 1.775 | Discriminator loss: 0.477\n",
            "Generator loss: 0.944 | Discriminator loss: 0.481\n",
            "Generator loss: 1.352 | Discriminator loss: 0.417\n",
            "Generator loss: 1.567 | Discriminator loss: 0.431\n",
            "Generator loss: 1.044 | Discriminator loss: 0.476\n",
            "Generator loss: 1.596 | Discriminator loss: 0.440\n",
            "Generator loss: 1.133 | Discriminator loss: 0.466\n",
            "Generator loss: 1.568 | Discriminator loss: 0.450\n",
            "Generator loss: 1.148 | Discriminator loss: 0.454\n",
            "Generator loss: 1.664 | Discriminator loss: 0.439\n",
            "Generator loss: 1.091 | Discriminator loss: 0.444\n",
            "Generator loss: 2.025 | Discriminator loss: 0.441\n",
            "Generator loss: 0.867 | Discriminator loss: 0.514\n",
            "Generator loss: 2.239 | Discriminator loss: 0.470\n",
            "Generator loss: 0.907 | Discriminator loss: 0.511\n",
            "Generator loss: 1.984 | Discriminator loss: 0.407\n",
            "Generator loss: 1.409 | Discriminator loss: 0.387\n",
            "Generator loss: 1.549 | Discriminator loss: 0.394\n",
            "Generator loss: 1.634 | Discriminator loss: 0.416\n",
            "Generator loss: 1.371 | Discriminator loss: 0.433\n",
            "Generator loss: 1.952 | Discriminator loss: 0.476\n",
            "Generator loss: 0.761 | Discriminator loss: 0.610\n",
            "Generator loss: 2.972 | Discriminator loss: 0.793\n",
            "Generator loss: 0.380 | Discriminator loss: 0.823\n",
            "Generator loss: 0.996 | Discriminator loss: 0.425\n",
            "Generator loss: 2.126 | Discriminator loss: 0.455\n",
            "Generator loss: 1.563 | Discriminator loss: 0.369\n",
            "Generator loss: 1.152 | Discriminator loss: 0.401\n",
            "Generator loss: 1.417 | Discriminator loss: 0.386\n",
            "Generator loss: 1.693 | Discriminator loss: 0.415\n",
            "Generator loss: 1.361 | Discriminator loss: 0.444\n",
            "Generator loss: 1.431 | Discriminator loss: 0.441\n",
            "Generator loss: 1.371 | Discriminator loss: 0.469\n",
            "Generator loss: 1.459 | Discriminator loss: 0.459\n",
            "Generator loss: 1.357 | Discriminator loss: 0.453\n",
            "Generator loss: 1.620 | Discriminator loss: 0.437\n",
            "Generator loss: 1.434 | Discriminator loss: 0.425\n",
            "Generator loss: 1.791 | Discriminator loss: 0.438\n",
            "Generator loss: 1.338 | Discriminator loss: 0.447\n",
            "Generator loss: 2.104 | Discriminator loss: 0.458\n",
            "Generator loss: 0.828 | Discriminator loss: 0.631\n",
            "Generator loss: 2.557 | Discriminator loss: 0.581\n",
            "Generator loss: 0.831 | Discriminator loss: 0.548\n",
            "Generator loss: 1.558 | Discriminator loss: 0.387\n",
            "Generator loss: 2.111 | Discriminator loss: 0.442\n",
            "Generator loss: 1.158 | Discriminator loss: 0.451\n",
            "Generator loss: 1.606 | Discriminator loss: 0.421\n",
            "Generator loss: 1.804 | Discriminator loss: 0.437\n",
            "Generator loss: 1.225 | Discriminator loss: 0.469\n",
            "Generator loss: 1.952 | Discriminator loss: 0.452\n",
            "Generator loss: 1.209 | Discriminator loss: 0.437\n",
            "Generator loss: 1.842 | Discriminator loss: 0.411\n",
            "Generator loss: 1.427 | Discriminator loss: 0.408\n",
            "Generator loss: 1.934 | Discriminator loss: 0.408\n",
            "Generator loss: 1.392 | Discriminator loss: 0.460\n",
            "Generator loss: 2.251 | Discriminator loss: 0.511\n",
            "Generator loss: 0.721 | Discriminator loss: 0.632\n",
            "Generator loss: 2.099 | Discriminator loss: 0.456\n",
            "Generator loss: 1.332 | Discriminator loss: 0.410\n",
            "Generator loss: 1.628 | Discriminator loss: 0.378\n",
            "Generator loss: 1.734 | Discriminator loss: 0.409\n",
            "Generator loss: 1.501 | Discriminator loss: 0.420\n",
            "Generator loss: 1.725 | Discriminator loss: 0.413\n",
            "Generator loss: 1.494 | Discriminator loss: 0.447\n",
            "Generator loss: 2.054 | Discriminator loss: 0.466\n",
            "Generator loss: 1.003 | Discriminator loss: 0.540\n",
            "Generator loss: 2.569 | Discriminator loss: 0.566\n",
            "Generator loss: 0.757 | Discriminator loss: 0.637\n",
            "Generator loss: 1.925 | Discriminator loss: 0.367\n",
            "Generator loss: 2.130 | Discriminator loss: 0.417\n",
            "Generator loss: 1.099 | Discriminator loss: 0.501\n",
            "Generator loss: 1.870 | Discriminator loss: 0.434\n",
            "Generator loss: 1.560 | Discriminator loss: 0.444\n",
            "Generator loss: 1.426 | Discriminator loss: 0.467\n",
            "Generator loss: 1.639 | Discriminator loss: 0.494\n",
            "Generator loss: 1.191 | Discriminator loss: 0.497\n",
            "Generator loss: 1.953 | Discriminator loss: 0.499\n",
            "Generator loss: 0.835 | Discriminator loss: 0.566\n",
            "Generator loss: 2.373 | Discriminator loss: 0.485\n",
            "Generator loss: 1.036 | Discriminator loss: 0.448\n",
            "Generator loss: 1.751 | Discriminator loss: 0.337\n",
            "Generator loss: 2.005 | Discriminator loss: 0.360\n",
            "Generator loss: 1.442 | Discriminator loss: 0.379\n",
            "Generator loss: 1.891 | Discriminator loss: 0.371\n",
            "Generator loss: 1.631 | Discriminator loss: 0.390\n",
            "Generator loss: 1.810 | Discriminator loss: 0.414\n",
            "Generator loss: 1.612 | Discriminator loss: 0.415\n",
            "Generator loss: 1.837 | Discriminator loss: 0.420\n",
            "Generator loss: 1.584 | Discriminator loss: 0.405\n",
            "Generator loss: 2.303 | Discriminator loss: 0.404\n",
            "Generator loss: 1.069 | Discriminator loss: 0.472\n",
            "Generator loss: 3.022 | Discriminator loss: 0.485\n",
            "Generator loss: 0.916 | Discriminator loss: 0.505\n",
            "Generator loss: 2.151 | Discriminator loss: 0.281\n",
            "Generator loss: 2.490 | Discriminator loss: 0.333\n",
            "Generator loss: 1.544 | Discriminator loss: 0.341\n",
            "Generator loss: 1.899 | Discriminator loss: 0.319\n",
            "Generator loss: 2.092 | Discriminator loss: 0.340\n",
            "Generator loss: 1.643 | Discriminator loss: 0.346\n",
            "Generator loss: 1.984 | Discriminator loss: 0.345\n",
            "Generator loss: 1.712 | Discriminator loss: 0.357\n",
            "Generator loss: 2.006 | Discriminator loss: 0.366\n",
            "Generator loss: 1.698 | Discriminator loss: 0.361\n",
            "Generator loss: 2.110 | Discriminator loss: 0.371\n",
            "Generator loss: 1.501 | Discriminator loss: 0.385\n",
            "Generator loss: 2.779 | Discriminator loss: 0.436\n",
            "Generator loss: 0.791 | Discriminator loss: 0.625\n",
            "Generator loss: 2.840 | Discriminator loss: 0.349\n",
            "Generator loss: 2.083 | Discriminator loss: 0.276\n",
            "Generator loss: 1.797 | Discriminator loss: 0.303\n",
            "Generator loss: 2.327 | Discriminator loss: 0.303\n",
            "Generator loss: 1.913 | Discriminator loss: 0.327\n",
            "Generator loss: 1.957 | Discriminator loss: 0.343\n",
            "Generator loss: 1.975 | Discriminator loss: 0.359\n",
            "Generator loss: 1.819 | Discriminator loss: 0.391\n",
            "Generator loss: 2.131 | Discriminator loss: 0.388\n",
            "Generator loss: 1.595 | Discriminator loss: 0.385\n",
            "Generator loss: 2.730 | Discriminator loss: 0.399\n",
            "Generator loss: 1.183 | Discriminator loss: 0.486\n",
            "Generator loss: 3.036 | Discriminator loss: 0.411\n",
            "Generator loss: 1.470 | Discriminator loss: 0.439\n",
            "Generator loss: 2.610 | Discriminator loss: 0.383\n",
            "Generator loss: 1.985 | Discriminator loss: 0.374\n",
            "Generator loss: 1.881 | Discriminator loss: 0.419\n",
            "Generator loss: 2.186 | Discriminator loss: 0.459\n",
            "Generator loss: 1.394 | Discriminator loss: 0.477\n",
            "Generator loss: 2.815 | Discriminator loss: 0.535\n",
            "Generator loss: 0.670 | Discriminator loss: 0.732\n",
            "Generator loss: 3.135 | Discriminator loss: 0.470\n",
            "Generator loss: 1.769 | Discriminator loss: 0.374\n",
            "Generator loss: 1.764 | Discriminator loss: 0.379\n",
            "Generator loss: 2.285 | Discriminator loss: 0.409\n",
            "Generator loss: 1.381 | Discriminator loss: 0.463\n",
            "Generator loss: 2.167 | Discriminator loss: 0.452\n",
            "Generator loss: 1.342 | Discriminator loss: 0.469\n",
            "Generator loss: 2.502 | Discriminator loss: 0.466\n",
            "Generator loss: 1.178 | Discriminator loss: 0.472\n",
            "Generator loss: 2.728 | Discriminator loss: 0.445\n",
            "Generator loss: 1.269 | Discriminator loss: 0.453\n",
            "Generator loss: 2.530 | Discriminator loss: 0.434\n",
            "Generator loss: 1.109 | Discriminator loss: 0.471\n",
            "Generator loss: 2.482 | Discriminator loss: 0.433\n",
            "Generator loss: 1.173 | Discriminator loss: 0.426\n",
            "Generator loss: 2.139 | Discriminator loss: 0.378\n",
            "Generator loss: 1.736 | Discriminator loss: 0.372\n",
            "Generator loss: 1.835 | Discriminator loss: 0.372\n",
            "Generator loss: 1.875 | Discriminator loss: 0.383\n",
            "Generator loss: 1.899 | Discriminator loss: 0.385\n",
            "Generator loss: 1.774 | Discriminator loss: 0.387\n",
            "Generator loss: 2.206 | Discriminator loss: 0.386\n",
            "Generator loss: 1.576 | Discriminator loss: 0.396\n",
            "Generator loss: 2.783 | Discriminator loss: 0.451\n",
            "Generator loss: 0.812 | Discriminator loss: 0.641\n",
            "Generator loss: 3.402 | Discriminator loss: 0.529\n",
            "Generator loss: 1.245 | Discriminator loss: 0.418\n",
            "Generator loss: 2.114 | Discriminator loss: 0.308\n",
            "Generator loss: 2.832 | Discriminator loss: 0.351\n",
            "Generator loss: 1.652 | Discriminator loss: 0.368\n",
            "Generator loss: 2.141 | Discriminator loss: 0.347\n",
            "Generator loss: 2.083 | Discriminator loss: 0.365\n",
            "Generator loss: 1.503 | Discriminator loss: 0.418\n",
            "Generator loss: 2.464 | Discriminator loss: 0.470\n",
            "Generator loss: 0.926 | Discriminator loss: 0.573\n",
            "Generator loss: 3.109 | Discriminator loss: 0.565\n",
            "Generator loss: 0.865 | Discriminator loss: 0.593\n",
            "Generator loss: 2.146 | Discriminator loss: 0.324\n",
            "Generator loss: 2.415 | Discriminator loss: 0.364\n",
            "Generator loss: 1.378 | Discriminator loss: 0.415\n",
            "Generator loss: 2.208 | Discriminator loss: 0.376\n",
            "Generator loss: 1.704 | Discriminator loss: 0.391\n",
            "Generator loss: 2.037 | Discriminator loss: 0.390\n",
            "Generator loss: 1.668 | Discriminator loss: 0.403\n",
            "Generator loss: 2.188 | Discriminator loss: 0.414\n",
            "Generator loss: 1.380 | Discriminator loss: 0.446\n",
            "Generator loss: 2.988 | Discriminator loss: 0.543\n",
            "Generator loss: 0.412 | Discriminator loss: 0.878\n",
            "Generator loss: 2.758 | Discriminator loss: 0.404\n",
            "Generator loss: 1.996 | Discriminator loss: 0.332\n",
            "Generator loss: 1.453 | Discriminator loss: 0.379\n",
            "Generator loss: 2.072 | Discriminator loss: 0.364\n",
            "Generator loss: 1.778 | Discriminator loss: 0.370\n",
            "Generator loss: 1.602 | Discriminator loss: 0.390\n",
            "Generator loss: 1.920 | Discriminator loss: 0.397\n",
            "Generator loss: 1.637 | Discriminator loss: 0.393\n",
            "Generator loss: 1.940 | Discriminator loss: 0.384\n",
            "Generator loss: 1.524 | Discriminator loss: 0.394\n",
            "Generator loss: 2.454 | Discriminator loss: 0.399\n",
            "Generator loss: 1.098 | Discriminator loss: 0.443\n",
            "Generator loss: 3.266 | Discriminator loss: 0.456\n",
            "Generator loss: 0.931 | Discriminator loss: 0.531\n",
            "Generator loss: 2.830 | Discriminator loss: 0.322\n",
            "Generator loss: 2.122 | Discriminator loss: 0.291\n",
            "Generator loss: 1.856 | Discriminator loss: 0.324\n",
            "Generator loss: 2.428 | Discriminator loss: 0.350\n",
            "Generator loss: 1.506 | Discriminator loss: 0.374\n",
            "Generator loss: 2.510 | Discriminator loss: 0.396\n",
            "Generator loss: 1.073 | Discriminator loss: 0.493\n",
            "Generator loss: 3.154 | Discriminator loss: 0.547\n",
            "Generator loss: 0.724 | Discriminator loss: 0.606\n",
            "Generator loss: 2.466 | Discriminator loss: 0.304\n",
            "Generator loss: 2.457 | Discriminator loss: 0.303\n",
            "Generator loss: 1.677 | Discriminator loss: 0.305\n",
            "Generator loss: 2.094 | Discriminator loss: 0.283\n",
            "Generator loss: 2.294 | Discriminator loss: 0.447\n"
          ]
        }
      ],
      "source": [
        "# Iterating over batches of data\n",
        "for data in data_gen:\n",
        "  # Splitting the random key into three parts for different purposes\n",
        "  key, key_generator, key_discriminator = jax.random.split(key, 3)\n",
        "\n",
        "  # Updating the generator state and calculating its loss\n",
        "  # The generator's loss and state are updated based on the discriminator's current state\n",
        "  # and the batch size determined by the current data\n",
        "  generator_state, generator_loss = generator_step(generator_state,\n",
        "                                                  discriminator_state,\n",
        "                                                  data.shape[0],\n",
        "                                                  key_generator)\n",
        "\n",
        "  # Updating the discriminator state and calculating its loss\n",
        "  # The discriminator's loss and state are updated based on both the generator's state\n",
        "  # and the real data from the current batch\n",
        "  discriminator_state, discriminator_loss = discriminator_step(generator_state,\n",
        "                                                              discriminator_state,\n",
        "                                                              data,\n",
        "                                                              data.shape[0],\n",
        "                                                              key)\n",
        "\n",
        "  message = f\"Generator loss: {generator_loss:.3f} | \"\n",
        "  message += f\"Discriminator loss: {discriminator_loss:.3f}\"\n",
        "  print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yldplD5aktw6"
      },
      "source": [
        "## Generate Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "49UKmBdwJA2v",
        "outputId": "47d9de7d-8720-4993-9306-0a705c3d9ca1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x2000 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate images\n",
        "z = np.random.randn(16, noise_dim)\n",
        "generated_images = generator.apply({'params': generator_state.params}, z)\n",
        "\n",
        "def show_generated_images(generated_images, num_images=10):\n",
        "    # Assuming generated_images is a numpy array of shape (n, height, width)\n",
        "    # We will display 'num_images' images in a grid\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i+1)\n",
        "        plt.imshow(generated_images[i].squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your generated images\n",
        "# Replace 'generated_images' with your actual array of generated images\n",
        "show_generated_images(generated_images)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
